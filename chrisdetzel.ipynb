{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d0da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# try to import known scrapers\n",
    "try:\n",
    "    from chrisdetzel_hbm import scrape_hbm_product\n",
    "except Exception:\n",
    "    scrape_hbm_product = None\n",
    "    \n",
    "try:\n",
    "    from chrisdetzel_holzprofi import scrape_holzprofi_product\n",
    "except Exception:\n",
    "    scrape_holzprofi_product = None\n",
    "        \n",
    "try:\n",
    "    from chrisdetzel_neureiter import scrape_neureiter_product\n",
    "except Exception:\n",
    "    scrape_neureiter_product = None\n",
    "\n",
    "try:\n",
    "    from chrisdetzel_idealo import scrape_idealo_product\n",
    "except Exception:\n",
    "    scrape_idealo_product = None\n",
    "\n",
    "def setup_headless_driver():\n",
    "    options = Options()\n",
    "    #options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()), options=options\n",
    "    )\n",
    "    return driver\n",
    "\n",
    "\n",
    "def _choose_url_column(df):\n",
    "    # Prefer column F (index 5). If not present, try to find a column containing 'url'\n",
    "    if len(df.columns) >= 6:\n",
    "        return df.columns[5]\n",
    "    for c in df.columns:\n",
    "        if 'url' in str(c).lower():\n",
    "            return c\n",
    "    raise ValueError('Konnte keine URL-Spalte finden (erwarte Spalte F oder eine Spalte mit \"url\").')\n",
    "\n",
    "def _domain_from_url(url):\n",
    "    try:\n",
    "        netloc = urlparse(str(url)).netloc.lower()\n",
    "        if netloc.startswith('www.'):\n",
    "            netloc = netloc[4:]\n",
    "        return netloc\n",
    "    except Exception:\n",
    "        return ''\n",
    "\n",
    "def _make_new_column_name(old_name, today_str):\n",
    "    return f\"{old_name}_{today_str}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8417c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xlsx_output_path = '/Users/gabrielhipp/Library/Mobile Documents/com~apple~CloudDocs/fiverr/chrisdetzel/Preisanalyse Wettbewerber v2.1_no_empty_row_short_test.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7faa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sheet\n",
    "sheet = 'Option 1 - nebeneinander'\n",
    "# Die erste Zeile war anfangs leer und die zweite Zeile enthielt den Header.\n",
    "# Daher header=1 verwenden\n",
    "df = pd.read_excel(test_xlsx_output_path, sheet_name=sheet, engine='openpyxl')\n",
    "\n",
    "# Verify that the first row is not empty (it must contain headers)\n",
    "first_row = df.iloc[0] if len(df) > 0 else None\n",
    "def _is_row_empty(row):\n",
    "    if row is None:\n",
    "        return True\n",
    "    for v in row:\n",
    "        if not (pd.isna(v) or str(v).strip() == ''):\n",
    "            return False\n",
    "    return True\n",
    "if _is_row_empty(first_row):\n",
    "    raise ValueError('first row shall always be the headers')\n",
    "\n",
    "url_col = _choose_url_column(df)\n",
    "\n",
    "# Determine last 4 columns to copy names from\n",
    "last4 = [\"Status\", \"Preis\", \"Lieferstatus\", \"Versandkosten\"]\n",
    "\n",
    "today_str = datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "new_col_names = [_make_new_column_name(str(c), today_str) for c in last4]\n",
    "\n",
    "# Prepare empty series for new columns\n",
    "new_cols = {name: pd.Series([pd.NA] * len(df), index=df.index, dtype=object) for name in new_col_names}\n",
    "\n",
    "# Domain -> function dispatch\n",
    "dispatch = {\n",
    "    'hbm-machines.com': scrape_hbm_product,\n",
    "    'holzprofi.com': scrape_holzprofi_product,\n",
    "    'neureiter-shop.at': scrape_neureiter_product,\n",
    "    'idealo.de': scrape_idealo_product,\n",
    "    'idealo.at': scrape_idealo_product,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6a1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using exact match for domain: idealo.de\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, row in df.iterrows():\n",
    "    url = row.get(url_col)\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        continue\n",
    "\n",
    "    domain = _domain_from_url(url)\n",
    "\n",
    "    scraper = None\n",
    "    # try exact match and suffix match\n",
    "    if domain in dispatch and dispatch[domain]:\n",
    "        scraper = dispatch[domain]\n",
    "        print(\"Using exact match for domain:\", domain)\n",
    "    else:\n",
    "        for k, v in dispatch.items():\n",
    "            if k and k in domain and v:\n",
    "                scraper = v\n",
    "                break\n",
    "\n",
    "    scraped = None\n",
    "    if scraper is None:\n",
    "        print(f\"No scraper available for this domain {domain} -> skip\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        driver = setup_headless_driver()\n",
    "        driver.get(url)\n",
    "        scraped = scraper(driver)\n",
    "        driver.quit()\n",
    "        print(f\"Scraped data for URL {url}: {scraped}\")\n",
    "    except Exception:\n",
    "        scraped = None\n",
    "\n",
    "    if not scraped:\n",
    "        continue\n",
    "\n",
    "    # Map scraped results into new columns heuristically\n",
    "    # Determine a simple mapping based on keywords in last4 column names\n",
    "    for new_col in new_col_names:\n",
    "        base = str(new_col).lower()\n",
    "        val = None\n",
    "        if 'preis' in base:\n",
    "            val = scraped['price']\n",
    "        elif 'lieferstatus' in base:\n",
    "            val = scraped['availability']\n",
    "        elif 'versandkosten' in base:\n",
    "            val = scraped['shipping_costs']\n",
    "        else: \"-\"\n",
    "        print(f\"val={val}\")\n",
    "        new_cols[new_col].iat[idx] = val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c920d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append new columns to df (they will be added at the end)\n",
    "for name, series in new_cols.items():\n",
    "    # if name collides, generate unique\n",
    "    final_name = name\n",
    "    counter = 1\n",
    "    while final_name in df.columns:\n",
    "        final_name = f\"{name}_{counter}\"\n",
    "        counter += 1\n",
    "    df[final_name] = series\n",
    "\n",
    "# Write back replacing only the sheet, preserving the rest of the workbook\n",
    "try:\n",
    "    # pandas >= 1.3 supports if_sheet_exists='replace'\n",
    "    with pd.ExcelWriter(test_xlsx_output_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
    "except TypeError:\n",
    "    # older pandas: load workbook, remove sheet then write\n",
    "    \n",
    "    wb = load_workbook(test_xlsx_output_path)\n",
    "    if sheet in wb.sheetnames:\n",
    "        std = wb[sheet]\n",
    "        wb.remove(std)\n",
    "    wb.save(test_xlsx_output_path)\n",
    "    with pd.ExcelWriter(test_xlsx_output_path, engine='openpyxl', mode='a') as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ecfb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
